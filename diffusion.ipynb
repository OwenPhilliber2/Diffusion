{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a19d8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "from unet import UNet\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Subset\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75a6ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "BATCH_SIZE = 128\n",
    "lr = 0.001\n",
    "T = 1000\n",
    "epochs = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d27d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing Data\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "folder_path = Path('data')\n",
    "\n",
    "if folder_path.is_dir():\n",
    "    download = False\n",
    "else:\n",
    "    download = True\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def prepare_dataset(label_list):\n",
    "    '''\n",
    "    Downloads and prepares the data\n",
    "\n",
    "    label_ind - index of the desired label to make the diffusion model on\n",
    "    The list is, ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "    '''\n",
    "    # Downloading and preparing the CIFAR-10 dataset\n",
    "    train_data = torchvision.datasets.CIFAR10('./data', train=True, download=download, transform=transform)\n",
    "    test_data = torchvision.datasets.CIFAR10('./data', train=False, download=download, transform=transform)\n",
    "\n",
    "    train_label_indices = [i for i, label in enumerate(train_data.targets) if label in label_list]\n",
    "    test_label_indices = [i for i, label in enumerate(test_data.targets) if label in label_list]\n",
    "\n",
    "    train = Subset(train_data, train_label_indices)\n",
    "    test = Subset(test_data, test_label_indices)\n",
    "\n",
    "    return torch.utils.data.ConcatDataset([train, test])\n",
    "\n",
    "def show_tensor_image(image):\n",
    "    reverse_transforms = transforms.Compose([\n",
    "        transforms.Lambda(lambda t: (t + 1) / 2),\n",
    "        transforms.Lambda(lambda t: t.permute(1, 2, 0)), # CHW to HWC\n",
    "        transforms.Lambda(lambda t: t * 255.),\n",
    "        transforms.Lambda(lambda t: t.numpy().astype(np.uint8)),\n",
    "        transforms.ToPILImage(),\n",
    "    ])\n",
    "\n",
    "    # Take first image of batch\n",
    "    if len(image.shape) == 4:\n",
    "        image = image[0, :, :, :] \n",
    "    plt.imshow(reverse_transforms(image))\n",
    "\n",
    "data = prepare_dataset([3, 4, 5, 7]) # cat, deer, dog, horse\n",
    "dataloader = DataLoader(data, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1424c777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying images from the dataset\n",
    "\n",
    "dataiter = iter(dataloader)\n",
    "images, labels = next(dataiter)\n",
    "img = images[0]\n",
    "img_np = img.numpy()\n",
    "show_tensor_image(img)\n",
    "plt.title(f\"Label: {labels[0].item()}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e87ac29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diffusion Utilities\n",
    "\n",
    "class Diffusion_Utils:\n",
    "    def __init__(self, num_timesteps=1000, cos_schedule = False, beta_start=1e-4, beta_end=2e-2, device=None):\n",
    "        self.device = device\n",
    "\n",
    "\n",
    "        if cos_schedule:\n",
    "            raise NotImplementedError(\"Cosine schedule not implemented yet\")\n",
    "        else:\n",
    "            self.betas = torch.linspace(start=beta_start, end=beta_end, steps=num_timesteps, device=self.device)\n",
    "\n",
    "        self.alphas = 1. - self.betas\n",
    "        self.alphas_cumprod = torch.cumprod(self.alphas, axis=0)\n",
    "        self.alphas_cumprod_prev = torch.cat([torch.tensor([1.0], device=self.device), self.alphas_cumprod[:-1]])\n",
    "        self.alphas_cumprod_next = torch.cat([self.alphas_cumprod[1:], torch.tensor([0.0], device=self.device)])\n",
    "\n",
    "        self.sqrt_alphas_cumprod = torch.sqrt(self.alphas_cumprod)\n",
    "        self.sqrt_one_minus_alphas_cumprod = torch.sqrt(1.0 - self.alphas_cumprod)\n",
    "        self.log_one_minus_alphas_cumprod = torch.log(1.0 - self.alphas_cumprod)\n",
    "        self.sqrt_recip_alphas = torch.sqrt(1.0 / self.alphas)\n",
    "        self.sqrt_recipm1_alphas_cumprod = torch.sqrt(1.0 / self.alphas_cumprod - 1)\n",
    "\n",
    "\n",
    "        self.posterior_variance = (\n",
    "            self.betas * (1.0 - self.alphas_cumprod_prev) / (1.0 - self.alphas_cumprod)\n",
    "        )\n",
    "\n",
    "    def q_sample(self, x_0, t, noise=None):\n",
    "        \"\"\" Diffuse image x_0 to timestep t\"\"\"\n",
    "        if noise is None:\n",
    "            noise = torch.randn_like(x_0)\n",
    "\n",
    "        sqrt_alphas_cumprod_t = self._get_index_from_list(self.sqrt_alphas_cumprod, t, x_0.shape)\n",
    "        sqrt_one_minus_alphas_cumprod_t = self._get_index_from_list(self.sqrt_one_minus_alphas_cumprod, t, x_0.shape)\n",
    "\n",
    "        return (\n",
    "            sqrt_alphas_cumprod_t * x_0\n",
    "            + sqrt_one_minus_alphas_cumprod_t * noise\n",
    "        ), noise\n",
    "    \n",
    "    def _get_index_from_list(self, vals, t, x_shape):\n",
    "        \"\"\" \n",
    "        Returns a specific index t of a passed list of values vals\n",
    "        while considering the batch dimension.\n",
    "        \"\"\"\n",
    "        batch_size = t.shape[0]\n",
    "        out = vals.gather(-1, t)\n",
    "        return out.reshape(batch_size, *((1,) * (len(x_shape) - 1))).to(t.device)\n",
    "    \n",
    "    def get_loss(self, model, x_0, t):\n",
    "        x_0 = x_0.to(self.device)\n",
    "        t = t.to(self.device)\n",
    "\n",
    "        x_noisy, noise = self.q_sample(x_0, t)\n",
    "        noise_pred = model(x_noisy, t)\n",
    "        \n",
    "        return F.mse_loss(noise, noise_pred)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")        \n",
    "model = UNet()\n",
    "diffusion_utils = Diffusion_Utils(num_timesteps=T, device=device)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa94174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling images and creating a plot of the denoising process\n",
    "\n",
    "@torch.no_grad()\n",
    "def sample_timestep(x, t):\n",
    "    \"\"\"\n",
    "    Calls the model to predict the noise in the image and returns \n",
    "    the denoised image. \n",
    "    Applies noise to this image, if we are not in the last step yet.\n",
    "    \"\"\"\n",
    "    betas_t = diffusion_utils._get_index_from_list(diffusion_utils.betas, t, x.shape)\n",
    "    sqrt_one_minus_alphas_cumprod_t = diffusion_utils._get_index_from_list(\n",
    "        diffusion_utils.sqrt_one_minus_alphas_cumprod, t, x.shape\n",
    "    )\n",
    "    \n",
    "    \n",
    "    \n",
    "    sqrt_recip_alphas_t = diffusion_utils._get_index_from_list(diffusion_utils.sqrt_recip_alphas, t, x.shape)\n",
    "    \n",
    "    model_mean = sqrt_recip_alphas_t * (\n",
    "        x - betas_t * model(x, t) / sqrt_one_minus_alphas_cumprod_t\n",
    "    )\n",
    "    \n",
    "    posterior_variance_t = diffusion_utils._get_index_from_list(diffusion_utils.posterior_variance, t, x.shape)\n",
    "    \n",
    "    if torch.all(t == 0):\n",
    "        return model_mean\n",
    "    else:\n",
    "        noise = torch.randn_like(x)\n",
    "        return model_mean + torch.sqrt(posterior_variance_t) * noise \n",
    "\n",
    "@torch.no_grad()\n",
    "def sample_plot_image(plot_steps = True):\n",
    "    \n",
    "    img_size = 32\n",
    "    img = torch.randn((1, 3, img_size, img_size), device=device)\n",
    "    if plot_steps:\n",
    "        plt.figure(figsize=(15,2))\n",
    "    else:\n",
    "        plt.figure(figsize=(5,5))\n",
    "    plt.axis('off')\n",
    "    num_images = 10\n",
    "    stepsize = int(T/num_images)\n",
    "\n",
    "    for i in range(0,T)[::-1]:\n",
    "        t = torch.full((1,), i, device=device, dtype=torch.long)\n",
    "        img = sample_timestep(img, t)\n",
    "        img_vis = torch.clamp(img, -1.0, 1.0)\n",
    "        if plot_steps:\n",
    "            if i % stepsize == 0:\n",
    "                plt.subplot(1, num_images, int(i/stepsize)+1)\n",
    "                show_tensor_image(img_vis.detach().cpu())\n",
    "    \n",
    "    if not plot_steps:\n",
    "        show_tensor_image(img_vis.detach().cpu())\n",
    "    \n",
    "    plt.show()            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05abe1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "\n",
    "from torch.optim import Adam\n",
    "\n",
    "print(\"Num params: \", sum(p.numel() for p in model.parameters()))\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "model.to(device)\n",
    "optimizer = Adam(model.parameters(), lr=lr)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for step, batch in enumerate(dataloader):\n",
    "      optimizer.zero_grad()\n",
    "\n",
    "      t = torch.randint(0, T, (BATCH_SIZE,), device=device).long()\n",
    "      loss = diffusion_utils.get_loss(model, batch[0], t)\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      if epoch % 100 == 0 and step % 100 == 0:\n",
    "        print(f\"Epoch {epoch} | step {step:03d} Loss: {loss.item()} \")\n",
    "        sample_plot_image()\n",
    "\n",
    "torch.save(model.state_dict(), './model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95739e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading pretrained model\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "state_dict = torch.load('./model.pth', map_location=torch.device(device))\n",
    "model = UNet()\n",
    "model.to(device)\n",
    "model.load_state_dict(state_dict)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4dca025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling one image\n",
    "\n",
    "sample_plot_image(plot_steps=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
